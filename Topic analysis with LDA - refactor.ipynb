{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Add something about how the campaigns were picked here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>page_name</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>time-warner-al-jazeera</td>\n",
       "      <td>us corporation</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;td id=boxholder&gt;\\r\\n&lt;table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>time-warner-al-jazeera</td>\n",
       "      <td>discrimination</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;td id=boxholder&gt;\\r\\n&lt;table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>401</td>\n",
       "      <td>hbo-animal-cruelty</td>\n",
       "      <td>us corporation</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;td id=boxholder&gt;\\r\\n&lt;table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>401</td>\n",
       "      <td>hbo-animal-cruelty</td>\n",
       "      <td>animal abuse</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;td id=boxholder&gt;\\r\\n&lt;table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_id               page_name        tag_name  \\\n",
       "0      400  time-warner-al-jazeera  us corporation   \n",
       "1      400  time-warner-al-jazeera  discrimination   \n",
       "2      401      hbo-animal-cruelty  us corporation   \n",
       "3      401      hbo-animal-cruelty    animal abuse   \n",
       "\n",
       "                                                                                                                                                                                                      html  \n",
       "0  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=boxholder>\\r\\n<table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...  \n",
       "1  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=boxholder>\\r\\n<table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...  \n",
       "2  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=boxholder>\\r\\n<table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...  \n",
       "3  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=boxholder>\\r\\n<table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the CSV file generated by SQL\n",
    "camp_txt = pd.read_csv('../capstone/text_fields.csv')\n",
    "camp_txt.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice that the structure above has one row for each tag. Campaigns with more than one tag are duplicated. In order to analyze the text, we want each campaign on one and only one row. This means flattening those tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>html</th>\n",
       "      <th>page_name</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;td id=boxholder&gt;\\r\\n&lt;table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...</td>\n",
       "      <td>time-warner-al-jazeera</td>\n",
       "      <td>us corporation, discrimination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;td id=boxholder&gt;\\r\\n&lt;table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...</td>\n",
       "      <td>hbo-animal-cruelty</td>\n",
       "      <td>us corporation, animal abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>402</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;td id=boxholder&gt;\\r\\n&lt;table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...</td>\n",
       "      <td>gm-strike</td>\n",
       "      <td>us corporation, working conditions, workers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>403</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;td id=boxholder&gt;\\r\\n&lt;table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...</td>\n",
       "      <td>boeing-dreamliner-fire</td>\n",
       "      <td>us corporation, consumer safety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_id  \\\n",
       "0      400   \n",
       "1      401   \n",
       "2      402   \n",
       "3      403   \n",
       "\n",
       "                                                                                                                                                                                                      html  \\\n",
       "0  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=boxholder>\\r\\n<table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...   \n",
       "1  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=boxholder>\\r\\n<table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...   \n",
       "2  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=boxholder>\\r\\n<table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...   \n",
       "3  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<td id=boxholder>\\r\\n<table style=border: 1px solid grey; margin-left: 10px; margin-bottom: 5px; width: 220px; cellspacing=0 c...   \n",
       "\n",
       "                page_name                                     tag_name  \n",
       "0  time-warner-al-jazeera               us corporation, discrimination  \n",
       "1      hbo-animal-cruelty                 us corporation, animal abuse  \n",
       "2               gm-strike  us corporation, working conditions, workers  \n",
       "3  boeing-dreamliner-fire              us corporation, consumer safety  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat = pd.DataFrame(camp_txt)\n",
    "\n",
    "def flatten_frame(df,col):  #df= DataFrame, col= the column to be flattened; in our case, 'tag_name'\n",
    "    headers = list(df.columns.values) #pull in the list of columns\n",
    "    group_cols = list(set(headers) - set([col])) #get the cols to group on by subtracting the one we are flattening\n",
    "    df = pd.DataFrame(df.groupby(by=(group_cols))[col].apply(list)).reset_index() #group and reset index\n",
    "    df[col] = df[col].apply(', '.join) #convert the flattened col of tags into a string\n",
    "    return df\n",
    "\n",
    "flat = flatten_frame(flat,'tag_name')\n",
    "flat.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now each campaign is on a single row, but we have to extract plain text from that ugly HTML/Django.  Luckily, a module called 'Beautiful Soup' will come to our rescue. While I am it, I'll take out all the punctuation from both the html and tag_name fields; we will need that done before the next stage of the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>html</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>tags_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;...</td>\n",
       "      <td>In a blatantly prejudiced move Time Warner Cable dropped CurrentTV the ...</td>\n",
       "      <td>us corporation, discrimination</td>\n",
       "      <td>us corporation  discrimination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;...</td>\n",
       "      <td>A new lawsuit claims that animal abuse by HBO led to the death of four ...</td>\n",
       "      <td>us corporation, animal abuse</td>\n",
       "      <td>us corporation  animal abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>402</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;...</td>\n",
       "      <td>This man has stitched his lips together and declared a hunger strike de...</td>\n",
       "      <td>us corporation, working conditions, workers</td>\n",
       "      <td>us corporation  working conditions  workers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>403</td>\n",
       "      <td>&lt;table cellspacing=0 cellpadding=0 align=right&gt;\\r\\n&lt;tbody&gt;\\r\\n&lt;tr&gt;\\r\\n&lt;...</td>\n",
       "      <td>Boeing s new 787 Dreamliners keep catching on fire  Something is clearl...</td>\n",
       "      <td>us corporation, consumer safety</td>\n",
       "      <td>us corporation  consumer safety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_id  \\\n",
       "0      400   \n",
       "1      401   \n",
       "2      402   \n",
       "3      403   \n",
       "\n",
       "                                                                         html  \\\n",
       "0  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<...   \n",
       "1  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<...   \n",
       "2  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<...   \n",
       "3  <table cellspacing=0 cellpadding=0 align=right>\\r\\n<tbody>\\r\\n<tr>\\r\\n<...   \n",
       "\n",
       "                                                                   text_clean  \\\n",
       "0  In a blatantly prejudiced move Time Warner Cable dropped CurrentTV the ...   \n",
       "1  A new lawsuit claims that animal abuse by HBO led to the death of four ...   \n",
       "2  This man has stitched his lips together and declared a hunger strike de...   \n",
       "3  Boeing s new 787 Dreamliners keep catching on fire  Something is clearl...   \n",
       "\n",
       "                                      tag_name  \\\n",
       "0               us corporation, discrimination   \n",
       "1                 us corporation, animal abuse   \n",
       "2  us corporation, working conditions, workers   \n",
       "3              us corporation, consumer safety   \n",
       "\n",
       "                                    tags_clean  \n",
       "0               us corporation  discrimination  \n",
       "1                 us corporation  animal abuse  \n",
       "2  us corporation  working conditions  workers  \n",
       "3              us corporation  consumer safety  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def clean_soup(df,old_col,new_col): # df=DataFrame, col=the column with the dirty HTML we want to clean\n",
    "    for index, item in df[old_col].iteritems(): #go row by row through the column\n",
    "        soup = BeautifulSoup(item, \"lxml\") #turn the current item into a BeautfulSoup object\n",
    "        washed = soup.get_text(\" \",strip=True) #get text from the soup object and store the text in the washed variable\n",
    "        df.set_value(index,new_col,washed) #update the clean data frame with the washed text\n",
    "    df[new_col] = df[new_col].str.replace('{(.+)}', ' ') #remove the django tags\n",
    "    return df\n",
    "\n",
    "def remove_punc(df,old_col,new_col):\n",
    "    df[new_col] = df[old_col].str.replace('[^\\w\\s]',' ') #replaces most punctuation with spaces\n",
    "    df[new_col] = df[new_col].str.replace('[_]',' ') #replaces underscores with spaces    \n",
    "    return df\n",
    "\n",
    "clean = pd.DataFrame(flat) #copy the results from the last step into a new frame\n",
    "\n",
    "clean['text_clean'] ='' #a new column for storing our squeaky-clean text\n",
    "clean['tags_clean'] = '' #a new column for storing our squeaky-clean tags\n",
    " \n",
    "clean = clean_soup(clean,'html','text_clean')\n",
    "clean = remove_punc(clean,'text_clean','text_clean')  \n",
    "clean = remove_punc(clean,'tag_name','tags_clean')\n",
    "\n",
    "pd.options.display.max_colwidth = 75\n",
    "clean[['page_id','html','text_clean','tag_name','tags_clean']].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At this point, we want to start whittling down this text to the words that will be most helpful for our analysis.  The first step is to remove all words that won't have value as predictors of the topic of the campaign.  Some of these are easy judgements- we know that we don't need extremely common words like conjunctions or pronouns.  But what about other types of words?  Common Nouns? Proper Nouns? Verbs? Adjectives?  Here we get to some value judgements that the computer can't make by itself, but I can write some helper functions that will give me the insight I need to make the decision.  This is where the Natural Language Toolkit (NLTK) comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import *\n",
    "#DAN: I would rather not import all these books, but I do need soething from the book module\n",
    "#Can't find a doc that explains all I am importing so I can be more selective!\n",
    "from nltk.book import *\n",
    "\n",
    "def filter_by_pos(df,old_col,new_col,pos_codes,num):\n",
    "    df[old_col] = df[old_col].str.lower()\n",
    "    df[new_col] = df.apply(lambda row: nltk.word_tokenize(row[old_col]), axis=1) #tokenize (pre-process) each word    \n",
    "    pos_tagged = nltk.pos_tag(df[new_col].sum())  #tag each word with a code indicating part of speech\n",
    "    pos_filtered = [word for word,pos in pos_tagged if pos in pos_codes]  #select all words matching my filter codes\n",
    "    pos_freq = FreqDist(pos_filtered).most_common(num) #get frequency of filtered words; return the top num\n",
    "    ##DAN: there must be some cool list comprehension way of doing this, but I couldn't figure it out (and I tried!!)\n",
    "    for index, row in df.iterrows():  #go through each campaign and remove out all words not in my filer\n",
    "        camp_filtered = [word for word in df[new_col][index] if word in pos_filtered]\n",
    "        df.set_value(index, new_col, camp_filtered)\n",
    "    return df, pos_freq\n",
    "\n",
    "filtered = pd.DataFrame(clean[['page_id','page_name','text_clean','tags_clean']]) #copy results of last step into a new frame\n",
    "                                                                                #dropped the old dirty columns!\n",
    "filtered['text_filtered'] = ''  #new column to store the text filtered by part of speech\n",
    "\n",
    "    \n",
    "pos_codes = ['JJ','NN','NNS']  #These codes indicate adjectives, common nouns, and plural common nouns.\n",
    "                                #I selected these codes after trial and error, trying different filters to see what gave me\n",
    "                                #the most important words with the least amount of semantic noise\n",
    "\n",
    "filtered, filtered_freq = filter_by_pos(filtered,'text_clean','text_filtered',pos_codes,10)\n",
    "\n",
    "filtered_freq  #this sorted frequency distribution helped me choose the pos codes I wanted to keep\n",
    "               #I'm only showing 10 here, but I reviewed many more while making the decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is what those words look like within each campaigns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "filtered[['page_id','text_clean','text_filtered']].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### That is the strongest list of words I could generate with a part of speech filter, but it still isn't great.  It has some random noise (like 's' and 't'),  generic words that are common in any text (like 'other' and 'last), and words that are very common in our specific campaigns, (like 'sumofus', 'petition' and 'profits').  But we want to be sure to keep all the words that could be predictive for us ('oil', 'water, 'palm', climate', 'food').  We can do that by applying a list of specific words, called stopwords, that we want to exclude from our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, I first need to grab the words from the 'tag_name' column and add them to the mailing text.  I couldn't do that until after I ran the part of speech filter, because NLTK needs to have sentences in context in order to  properly mark the part of speech; adding short phrases would have created problems.  But from here on in, I will be dealing with collections of words, where the order doesn't matter.  Because the tags were specifically chosen to convey topic information, I have chosen to give them 3x more weight than the regular mailing text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def concat_cols(df, filtered_col, unfiltered_col, new_col, coef):\n",
    "    weighted = ((df[unfiltered_col].str.lower()+' ')*coef) #multiply the unfiltered column by the desired coefficient\n",
    "    df[new_col] = weighted.apply(lambda row: nltk.word_tokenize(row)) #tokenize (pre-process) each word \n",
    "    df[new_col] = df[new_col] + df[filtered_col]\n",
    "    #df[new_col] = merged.str.lower()\n",
    "    return df\n",
    "\n",
    "merged = pd.DataFrame(filtered[['page_id','page_name','text_filtered','tags_clean']]) #copy results of last step into a new frame\n",
    "merged['text_merged'] = '' # for combined result of text and tags                     \n",
    "\n",
    "merged = concat_cols(merged,'text_filtered','tags_clean','text_merged',3)\n",
    "merged.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That taken care of, I can focus on the stop words.   I already have a list of generic stopwords to get me started, but others I have to add by hand.  Again, I can write a helper program in NLTK to make it easier.  I will display all the words by frequency again, just like when we were doing the past of speech filtering, but this time I will also subtract my generic list of stopwords.  When I look through the list of what is left, I will undoubtedly find more stop words, so I will do it again, and again ... this is a manual process, but it the end we end up with a list of highly relevant words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def exclude_stopwords(df,old_col,new_col,num):\n",
    "    stop_words = set(stopwords.words('english')) #read in my text file of stopwords   \n",
    "    df[new_col] = df[old_col].apply(lambda x:[item for item in x if item not in stop_words]) #remove the stop words\n",
    "    ready_freq = FreqDist(df[new_col].sum()).most_common(num) #return the top words that are left by frequency\n",
    "    return ready, ready_freq\n",
    "\n",
    "ready = pd.DataFrame(merged[['page_id','page_name','text_merged']]) #copy results of last step into a new frame\n",
    "ready['text_ready'] = ''\n",
    "    \n",
    "ready, ready_freq = exclude_stopwords(ready,'text_merged','text_ready',10)\n",
    "\n",
    "ready_freq #I use this list to find common words that I don't want in my analysis, then manually add them the stoplist\n",
    "\n",
    "ready_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Now, at long last, we are finally able to get to the good stuff and build our model!  The first step is to take our painstakingly cleaned and filtered text and create a giant \"bag of words\", called a corpus, to feed into a Latent Dirichlet Allocation (LDA) model.  Finally we will see some actual topics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "def generate_lda(df,col,topics,words):\n",
    "    camp_corpus = df[col].tolist()\n",
    "    dictionary = corpora.Dictionary(camp_corpus)\n",
    "    corpus = [dictionary.doc2bow(text) for text in camp_corpus]\n",
    "    lda = models.ldamodel.LdaModel(corpus, num_topics=topics, id2word = dictionary, passes=75)\n",
    "    topics = lda.print_topics(num_topics=topics,num_words=words)\n",
    "    return lda, corpus, dictionary, topics\n",
    "\n",
    "lda, corpus, dictionary, all_topics = generate_lda(ready,'text_ready',15,3)\n",
    "\n",
    "all_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "vis = pyLDAvis.gensim.prepare(lda, corpus, dictionary)\n",
    "pyLDAvis.display(vis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
